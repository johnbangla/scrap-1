{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422a3f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup \n",
    "import requests \n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "058d75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = [] # Create a list to store the descriptions\n",
    "processors=[]\n",
    "ram=[]\n",
    "os=[]\n",
    "storage=[]\n",
    "inches=[]\n",
    "warranty=[]\n",
    "prices = []\n",
    "ratings = []\n",
    "productlinks = []\n",
    "lis = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df54c2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Product title1062+ Total Ratings1062Total Prices488\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8332/2208301278.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'Description'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdescriptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m504\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Ratings'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m504\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Prices'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mprices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m504\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Finally merging all the features into a single dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Mydata.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\scrapenv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\scrapenv\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     return arrays_to_mgr(\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\scrapenv\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\scrapenv\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "\n",
    "pages = list(range(1,20))\n",
    "for page in pages:\n",
    "  req = requests.get(\"https://www.trendyol.com/tablo-x-c1185?pi={}\".format(page)).text  # URL of the website which you want to scrape\n",
    "  #content = req.content # Get the content\n",
    "  soup = BeautifulSoup(req,'html.parser')\n",
    "  #print(soup.prettify())\n",
    "\n",
    "  desc = soup.find_all('span' , class_='prdct-desc-cntnr-name hasRatings')\n",
    "  for i in range(len(desc)):\n",
    "      descriptions.append(desc[i].text)\n",
    "  len(descriptions)\n",
    "\n",
    "  rating = soup.find_all('span',class_='ratingCount') \n",
    "   #Extracting the ratings of each laptop from the website   \n",
    "  for i in range(len(rating)):                      \n",
    "    ratings.append(rating[i].text)\n",
    "    len(ratings)\n",
    "  # Extracting price of each laptop from the website\n",
    "  price = soup.find_all('div',class_='prc-box-sllng prc-box-sllng-w-dscntd') \n",
    "  for i in range(len(price)):\n",
    "    prices.append(price[i].text)\n",
    "    len(prices)\n",
    "  links = soup.findAll('div', class_='p-card-chldrn-cntnr')\n",
    "  for link in links:\n",
    "    p_link = link.find('a').get('href')\n",
    "    base_url = 'https://www.trendyol.com'\n",
    "    complete_link = base_url + p_link\n",
    "    productlinks.append(complete_link)\n",
    "    #The below code is responsible for downloading Images of each product\n",
    "#   for eachlink in productlinks:\n",
    "#     res = requests.get(eachlink).text\n",
    "#     each_product_soup =  BeautifulSoup(res,'html.parser')\n",
    "#     img_tags =  each_product_soup.find_all('img')\n",
    "\n",
    "#     urls = [img['src'] for img in img_tags]\n",
    "\n",
    "\n",
    "#     for url in urls:\n",
    "#         filename = re.search(r'/([\\w_-]+[.](jpg|gif|png))$', url)\n",
    "#         if not filename:\n",
    "#              print(\"Regex didn't match with the url: {}\".format(url))\n",
    "#              continue\n",
    "#         with open(filename.group(1), 'wb') as f:\n",
    "#             if 'http' not in url:\n",
    "#                 # sometimes an image source can be relative \n",
    "#                 # if it is provide the base url which also happens \n",
    "#                 # to be the site variable atm. \n",
    "#                 url = '{}{}'.format(eachlink, url)\n",
    "#             response = requests.get(url)\n",
    "#             f.write(response.content)\n",
    "            #Images download complete\n",
    "            \n",
    "            \n",
    "            \n",
    "#     details =  each_product_soup.find_all('li')\n",
    "    \n",
    "#     for ul in  details:\n",
    "#         print(ul.text)\n",
    "#         for li in ul.findAll('li'):\n",
    "# #             if li.find('ul'):\n",
    "# #                 break\n",
    "#             lis.append(li)\n",
    "\n",
    "#     for li in lis:\n",
    "#         print (li.text)\n",
    "# print(len(descriptions))\n",
    "# print(descriptions)    \n",
    "    \n",
    "# print(ratings) \n",
    "# print(len(ratings)) \n",
    "\n",
    "# print(prices)\n",
    "\n",
    "\n",
    "print('Total Product title' + '' + str(len(descriptions)) + '+ ''Total Ratings' + str(len(ratings)) + 'Total Prices' + str(len(prices)) )\n",
    "# print(productlinks)\n",
    "#   commonclass = soup.find_all('li',class_='tVe95H') # We observe that the classnames for the different specifications are under one div.So we need to apply some method to extract the different features.\n",
    "#   # Create empty lists for the features\n",
    "#   for i in range(0,len(commonclass)):\n",
    "#     p=commonclass[i].text # Extracting the text from the tags\n",
    "#     if(\"Core\" in p): \n",
    "#         processors.append(p)\n",
    "#     elif(\"RAM\" in p): \n",
    "#         ram.append(p)\n",
    "#     elif(\"HDD\" in p or \"SSD\" in p):\n",
    "#         storage.append(p)\n",
    "#     elif(\"Operating\" in p):\n",
    "#         os.append(p)\n",
    "#     elif(\"Display\" in p):\n",
    "#         inches.append(p)\n",
    "#     elif(\"Warranty\" in p):\n",
    "#         warranty.append(p)\n",
    "\n",
    "\n",
    "df = {'Description':descriptions[slice(504)],'Ratings':ratings[slice(504)],'Prices':prices[slice(504)]}\n",
    "dataset = pd.DataFrame(data = df) # Finally merging all the features into a single dataframe\n",
    "dataset\n",
    "dataset.to_csv('Mydata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Mydata.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('TestDB1.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da6a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('CREATE TABLE IF NOT EXISTS etable (Id, Description, Ratng, Price)')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e5835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('etable', conn, if_exists='replace', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9638dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c.execute('''SELECT * FROM etable''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb8a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in c.fetchall():\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
